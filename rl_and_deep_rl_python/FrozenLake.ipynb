{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a02af5aa-6d1a-4829-957f-f84ffc1e6628",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gymnasium as gym \n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5a9d316-a3cf-4abb-b13d-6686412c3710",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_headless = gym.make('FrozenLake-v1',is_slippery=False)\n",
    "env_graphic = gym.make(\"FrozenLake-v1\", render_mode=\"human\", is_slippery=False)\n",
    "env = env_headless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb3dea02-f3a4-4f81-aa67-0e126a5a6e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Discrete(4), Discrete(16))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_space_size = env.action_space.n\n",
    "state_space_size = env.observation_space.n\n",
    "env.action_space, env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a63b1f0-3d03-496f-a397-d103bbda68d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "qtable = np.zeros((state_space_size, action_space_size))\n",
    "print(qtable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b3e41ce-515c-4988-a950-f448a0db9aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_episodes = 5000\n",
    "learning_rate = 0.2\n",
    "max_steps = 100\n",
    "gamma = 0.9\n",
    "epsilon = 1\n",
    "max_epsilon = 1\n",
    "min_epsilon = 0.01\n",
    "decay_rate = 0.001\n",
    "total_runs = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e670d6d-147d-42eb-9020-51ef41d7b276",
   "metadata": {},
   "source": [
    "## Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a48dc3ab-8700-4ebb-bf2a-fa127616c4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress at  0\n",
      "Progress at  500\n",
      "Progress at  1000\n",
      "Progress at  1500\n",
      "Progress at  2000\n",
      "Progress at  2500\n",
      "Progress at  3000\n",
      "Progress at  3500\n",
      "Progress at  4000\n",
      "Progress at  4500\n",
      "Total runs:  5000 Score: 0.7594\n"
     ]
    }
   ],
   "source": [
    "for blah in range(1):\n",
    "    rewards = []\n",
    "    for episode in range(total_episodes):\n",
    "        if episode % 500 == 0:\n",
    "            print(\"Progress at \", episode)\n",
    "            env = env_graphic\n",
    "        else:\n",
    "            env = env_headless\n",
    "        state = env.reset()[0]\n",
    "        step = 0\n",
    "        done = False\n",
    "        total_rewards = 0\n",
    "        total_runs = total_runs+1\n",
    "        for step in range(max_steps):\n",
    "            if random.uniform(0,1) > epsilon:\n",
    "                action = np.argmax(qtable[state,:])\n",
    "            else:\n",
    "                action = env.action_space.sample()\n",
    "    \n",
    "            new_state, reward, done, info, extra = env.step(action)\n",
    "    \n",
    "    #        print(state, new_state, reward, done)\n",
    "            \n",
    "            max_new_state = np.max(qtable[new_state, :])\n",
    "            \n",
    "            qtable[state,action] = (1 - learning_rate) * qtable[state,action] + learning_rate * (reward + gamma * max_new_state - qtable[state, action])\n",
    "            total_rewards += reward\n",
    "            state = new_state\n",
    "        \n",
    "            if done:\n",
    "                rewards.append(total_rewards)\n",
    "                break\n",
    "    \n",
    "            epsilon = min_epsilon + (max_epsilon - min_epsilon) * np.exp(-decay_rate * episode)\n",
    "            \n",
    "    print(\"Total runs: \", total_runs, \"Score:\", str(sum(rewards)/total_episodes))\n",
    "#print(qtable)\n",
    "#total_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d2c2b44-b582-44cb-ad0c-a2935663f34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1\n"
     ]
    }
   ],
   "source": [
    "env = env_graphic\n",
    "env.reset()\n",
    "\n",
    "for episode in range(1):\n",
    "    state = env.reset()[0]\n",
    "    step = 0\n",
    "    done = False\n",
    "\n",
    "    print(\"Episode:\", episode+1)\n",
    "    for step in range(max_steps):\n",
    "        action = np.argmax(qtable[state,:])\n",
    "        new_state, reward, done, info, extra = env.step(action)\n",
    "        if done:\n",
    "            print(\"num of steps\", step)\n",
    "            break;\n",
    "        state = new_state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1373dc7c-92dd-4bd2-9a90-d6d405d4842b",
   "metadata": {},
   "source": [
    "## SARSA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64b1dab7-46fe-4495-8c10-280575250dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress at  0\n",
      "Progress at  200\n",
      "Progress at  400\n",
      "Progress at  600\n",
      "Progress at  800\n",
      "Progress at  1000\n",
      "Progress at  1200\n",
      "Progress at  1400\n",
      "Progress at  1600\n",
      "Progress at  1800\n",
      "Progress at  2000\n",
      "Progress at  2200\n",
      "Progress at  2400\n",
      "Progress at  2600\n",
      "Progress at  2800\n",
      "Progress at  3000\n",
      "Progress at  3200\n",
      "Progress at  3400\n",
      "Progress at  3600\n",
      "Progress at  3800\n",
      "Progress at  4000\n",
      "Progress at  4200\n",
      "Progress at  4400\n",
      "Progress at  4600\n",
      "Progress at  4800\n",
      "Total runs:  5000 Score: 0.7624\n",
      "[[0.00415188 0.00922641 0.00922641 0.00415188]\n",
      " [0.00415188 0.         0.02050313 0.00922641]\n",
      " [0.00922641 0.0455625  0.00922605 0.02050312]\n",
      " [0.02050301 0.         0.00904469 0.00915977]\n",
      " [0.00922641 0.02050313 0.         0.00415188]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.10125    0.         0.02050312]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.02050313 0.         0.0455625  0.00922641]\n",
      " [0.02050313 0.10125    0.10125    0.        ]\n",
      " [0.0455625  0.225      0.         0.0455625 ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.10125    0.225      0.0455625 ]\n",
      " [0.10125    0.225      0.5        0.10125   ]\n",
      " [0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "qtable = np.zeros((state_space_size, action_space_size))\n",
    "\n",
    "for blah in range(1):\n",
    "    rewards = []\n",
    "    for episode in range(total_episodes):\n",
    "        if episode % 200 == 0:\n",
    "            print(\"Progress at \", episode)\n",
    "            env = env_graphic\n",
    "        else:\n",
    "            env = env_headless\n",
    "        state = env.reset()[0]\n",
    "        step = 0\n",
    "        done = False\n",
    "        total_rewards = 0\n",
    "        total_runs = total_runs+1\n",
    "        for step in range(max_steps):\n",
    "            if random.uniform(0,1) > epsilon:\n",
    "                action = np.argmax(qtable[state,:])\n",
    "            else:\n",
    "                action = env.action_space.sample()\n",
    "\n",
    "            \n",
    "            if random.uniform(0,1) > epsilon:\n",
    "                new_action = np.argmax(qtable[state,:])\n",
    "            else:\n",
    "                new_action = env.action_space.sample()\n",
    "\n",
    "            new_state, reward, done, info, extra = env.step(action)\n",
    "\n",
    "            if random.uniform(0,1) > epsilon:\n",
    "                new_action = np.argmax(qtable[new_state,new_action])\n",
    "            else:\n",
    "                new_action = env.action_space.sample()\n",
    "\n",
    "    #        print(state, new_state, reward, done)\n",
    "            \n",
    "            sarsa_new_state = np.max(qtable[new_state, :])\n",
    "            \n",
    "            qtable[state,action] = (1 - learning_rate) * qtable[state,action] + learning_rate * (reward + gamma * sarsa_new_state - qtable[state, action])\n",
    "            total_rewards += reward\n",
    "            state = new_state\n",
    "        \n",
    "            if done:\n",
    "                rewards.append(total_rewards)\n",
    "                break\n",
    "    \n",
    "            epsilon = min_epsilon + (max_epsilon - min_epsilon) * np.exp(-decay_rate * episode)\n",
    "            \n",
    "    print(\"Total runs: \", total_runs, \"Score:\", str(sum(rewards)/total_episodes))\n",
    "print(qtable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef6215cb-2397-45b2-ba7c-863504fedbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_headless.close()\n",
    "env_graphic.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c03fa34-dc6a-4c3e-82e7-ef3b47cc8e14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
